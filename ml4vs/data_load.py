import numpy as np
import pandas as pd


def shift_log_transform(df, name, shift):
    df[name] = np.log(df[name] + shift)


def load_data(fnames, names, names_to_delete):
    """
    Function that loads data from series of files where first file contains
    class of zeros and other files - classes of ones.

    :param fnames:
        Iterable of file names.
    :param names:
        Names of columns in files.
    :param names_to_delete:
        Column names to delete.
    :return:
        X, y - ``sklearn`` arrays of features & responces.
    """
    # Load data
    dfs = list()
    for fn in fnames:
        dfs.append(pd.read_table(fn, names=names, engine='python',
                                 na_values='+inf', sep=r"\s*",
                                 usecols=range(30)))

    # # Remove meaningless features
    # delta = list()
    # for df in dfs:
    #     delta.append(df['CSSD'].min())
    # delta = np.min([d for d in delta if not np.isinf(d)])
    # print "delta = {}".format(delta)
    delta = None

    for df in dfs:
        for name in names_to_delete:
            del df[name]
        # try:
        #     shift_log_transform(df, 'CSSD', -delta + 0.1)
        # except KeyError:
        #     pass

    # List of feature names
    features_names = list(dfs[0])
    # Count number of NaN for each feature
    for i, df in enumerate(dfs):
        print("File {}".format(i))
        for feature in features_names:
            print("Feature {} has {} NaNs".format(feature,
                                                  df[feature].isnull().sum()))
        print("=======================")

    # Concatenate dfs
    df = pd.concat(dfs, axis=0)
    # df['boolNXS'] = np.array(df['NXS'] == 0, dtype=int)
    # df = pd.get_dummies(df, columns=['boolNXS'])
    features_names = list(df)

    # Convert to numpy arrays
    X = np.array(df[list(features_names)].values, dtype=float)
    # Responses
    y = np.zeros(len(X))
    y[len(dfs[0]):] = np.ones(len(X) - len(dfs[0]))

    df['variable'] = np.array(y, dtype=int)

    return X, y, df, features_names, delta


def load_data_tgt(fname, names, names_to_delete, delta):
    """
    Function that loads target data for classification.

    :param fname:
        Target data file.
    :param names:
        Names of columns in files.
    :param names_to_delete:
        Column names to delete.
    :return:
        X, ``sklearn`` array of features, list of feature names
    """
    # Load data
    df = pd.read_table(fname, names=names, engine='python', na_values='+inf',
                       sep=r"\s*", usecols=range(30))

    for name in names_to_delete:
        del df[name]
    # try:
    #     shift_log_transform(df, 'CSSD', -delta + 0.1)
    # except KeyError:
    #     pass

    # List of feature names
    features_names = list(df)
    # Count number of NaN for each feature
    for feature in features_names:
        print("Feature {} has {} NaNs".format(feature,
                                              df[feature].isnull().sum()))
    print("=======================")

    # df['boolNXS'] = np.array(df['NXS'] == 0, dtype=int)
    # df = pd.get_dummies(df, columns=['boolNXS'])
    features_names = list(df)

    # Convert to numpy arrays
    # Features
    X = np.array(df[list(features_names)].values, dtype=float)

    # Original data
    df_orig = pd.read_table(fname, names=names, engine='python', na_values='+inf',
                            sep=r"\s*", usecols=range(30))

    return X, features_names, df, df_orig
